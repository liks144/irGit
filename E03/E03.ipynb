{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import string\n",
    "import math\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "userProp = [\"username\",\"text\",\"tweetid\"]\n",
    "postings = defaultdict(dict)\n",
    "visit = defaultdict(dict)\n",
    "Querylist = []\n",
    "Length = defaultdict(dict)\n",
    "docN = 0\n",
    "TOPK = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postings():\n",
    "    global postings\n",
    "    global docN\n",
    "    f = open(r'/home/liks/Documents/实验/IR/实验03/tweets.txt')\n",
    "    lines = f.readlines()#readlines()\n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        i += 1\n",
    "        line = tokenize_tweet(line)\n",
    "        tweetid = line[0]\n",
    "        line.pop(0)\n",
    "        Length[tweetid]=len(line)\n",
    "       # termlist 是一个（词项：词频）的 列表\n",
    "        termlist = [(k,v) for k,v in collections.Counter(line).items()]\n",
    "        for te in termlist:\n",
    "            if te[0] in postings.keys():\n",
    "                postings[te[0]].append((tweetid,te[1]))\n",
    "            else:\n",
    "                postings[te[0]] = [(tweetid,te[1])]\n",
    "    docN = i\n",
    "    # 这样出来的posting就是一个这样的东西（字典） posting[] :\n",
    "    #                                         |\n",
    "    #                                        |->term1:[(tweetid,fq),(tweetid,fq)...]\n",
    "    #                                       |->term2:[(tweetid,fq),(tweetid,fq)...]\n",
    "    #                                       ->term3:[(tweetid,fq)...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    global postings\n",
    "    global docN\n",
    "    if term in postings.keys():\n",
    "        return math.log(docN/len(postings[term]))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfwght_query(term):\n",
    "    global Querylist\n",
    "#     [(k,v) for k,v in collections.Counter(a).items()]\n",
    "    return (1+math.log(collections.Counter(Querylist)[term]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search_document(documentID):\n",
    "#     锁定一个document，计算这个document与当前query的打分\n",
    "#     这个函数里，在get一下query的tf 直接都在这里算出来 因为tf_raw在这里\n",
    "    global Querylist\n",
    "    global Length\n",
    "    tf_raw = []\n",
    "    Score = 0\n",
    "    for i in range(len(Querylist)):\n",
    "        tfx = checkin(Querylist[i],documentID)\n",
    "        tf_raw.append(tfx)\n",
    "    for t in tf_raw:\n",
    "        if t == 0:\n",
    "            tf_wght = 0\n",
    "        else:\n",
    "            tf_wght = (1+math.log(t))\n",
    "    NORMALIZE = math.sqrt(sum(w**2 for w in tf_raw))\n",
    "    term_normalized = [ num/NORMALIZE for num in tf_raw]\n",
    "    for i in range(len(Querylist)):\n",
    "        Score += tfwght_query(Querylist[i])*idf(Querylist[i])*term_normalized[i]\n",
    "#     Score = Score/Length[documentID]\n",
    "    return Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkin(term,documentID):\n",
    "#     计算document中是否包含term，如果包含 返回包含多少 没有就返回0\n",
    "    global postings\n",
    "    if term not in postings.keys():\n",
    "        return 0\n",
    "#     elif documentID in [te[1] for te in postings[term] ]\n",
    "    else:\n",
    "        for docid in postings[term]:\n",
    "            if docid[0]==documentID:\n",
    "                return docid[1]\n",
    "    return 0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "#     posting 是badge中保存每一个文档id所用到的类\n",
    "    def __init__(self):\n",
    "        self.documentid = 0\n",
    "        self.tf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class badge:\n",
    "#     这是postings中的一个值\n",
    "#     postings -> term:badge{df,postings{documentID,tf}} （df Query里要用到）\n",
    "    def __init__(self):\n",
    "        self.df = 0\n",
    "        self.Document = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(string):\n",
    "#     返回一个 列表 ，包括 username、tweetcontent和tweetid     最后的结果中不包含这三个字段\n",
    "#     列表第一个值是tweetid 然后是content     [tweetid,content]\n",
    "    string=string.lower()\n",
    "    a = string.index(\"username\")\n",
    "    b = string.index(\"clusterno\")\n",
    "    c = string.rindex(\"tweetid\")-1\n",
    "    d = string.rindex(\"errorcode\")\n",
    "    e = string.index(\"text\")\n",
    "    f = string.index(\"timestr\")-3\n",
    "    #提取用户名、tweet内容和tweetid三部分主要信息\n",
    "    string = string[c:d]+string[a:b]+string[e:f]\n",
    "    # print(string)\n",
    "    terms=TextBlob(string).words.singularize()\n",
    "    # print(terms)\n",
    "\n",
    "    result=[]\n",
    "    for word in terms:\n",
    "        expected_str = Word(word)\n",
    "        expected_str = expected_str.lemmatize(\"v\")\n",
    "        if expected_str not in userProp:\n",
    "            result.append(expected_str)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(query):\n",
    "#     返回的就是Querylist\n",
    "    query = query.lower()\n",
    "    terms=TextBlob(query).words.singularize()\n",
    "\n",
    "    result=[]\n",
    "    for word in terms:#query和term做同样的处理\n",
    "        expected_str = Word(word)\n",
    "        expected_str = expected_str.lemmatize(\"v\")\n",
    "        result.append(expected_str)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search(query):\n",
    "    global Querylist\n",
    "    global visit\n",
    "    global TOPK\n",
    "    Querylist = token(query)\n",
    "#     print(Querylist)\n",
    "    for TERM in Querylist:\n",
    "#         print('now it turns to %s'%TERM)\n",
    "        if TERM in postings.keys():\n",
    "#             print('%s in postings.keys()'%TERM)\n",
    "            for doc in postings[TERM]:\n",
    "                if doc[0] not in visit.keys():\n",
    "                    visit[doc[0]] = Search_document(doc[0])\n",
    "\n",
    "    return(sorted(visit.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)[:TOPK])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_postings()\n",
    "# 启动函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('28977078074343425', 10.828621111080203),\n",
       " ('625192875345768448', 8.02446940301423),\n",
       " ('31831410260058113', 8.02446940301423),\n",
       " ('317377292047376387', 8.02446940301423),\n",
       " ('30172846525251585', 8.02446940301423),\n",
       " ('30172275693068288', 8.02446940301423),\n",
       " ('30147216362446848', 8.02446940301423),\n",
       " ('29980635686772738', 8.02446940301423),\n",
       " ('34780760116305920', 7.619004294906064),\n",
       " ('34635341382025216', 7.619004294906064),\n",
       " ('33659477823590400', 7.619004294906064),\n",
       " ('33192271625064448', 7.619004294906064),\n",
       " ('33191722632613889', 7.619004294906064),\n",
       " ('33133626308698113', 7.619004294906064),\n",
       " ('32955696215498752', 7.619004294906064),\n",
       " ('32874160988356608', 7.619004294906064),\n",
       " ('32652240711852032', 7.619004294906064),\n",
       " ('30996863431745536', 7.619004294906064),\n",
       " ('302154195702800384', 7.619004294906064),\n",
       " ('303966009197469696', 4.915531143865067),\n",
       " ('626540723328970752', 1.6862287441467623),\n",
       " ('626514865423785984', 1.6862287441467623),\n",
       " ('626513707800117248', 1.6862287441467623),\n",
       " ('626513632302637056', 1.6862287441467623),\n",
       " ('626510398510858240', 1.6862287441467623),\n",
       " ('626507277944664064', 1.6862287441467623),\n",
       " ('626502248982515712', 1.6862287441467623),\n",
       " ('626495089309696001', 1.6862287441467623),\n",
       " ('626494036543565824', 1.6862287441467623),\n",
       " ('626492799223906305', 1.6862287441467623),\n",
       " ('626492333626933249', 1.6862287441467623),\n",
       " ('626490874034319361', 1.6862287441467623),\n",
       " ('626486809745186816', 1.6862287441467623),\n",
       " ('626482309257134080', 1.6862287441467623),\n",
       " ('626481139025334272', 1.6862287441467623),\n",
       " ('626473098565578753', 1.6862287441467623),\n",
       " ('626471987066634240', 1.6862287441467623),\n",
       " ('626467469792669696', 1.6862287441467623),\n",
       " ('626464739325952000', 1.6862287441467623),\n",
       " ('626464651220512768', 1.6862287441467623),\n",
       " ('626464118556463108', 1.6862287441467623),\n",
       " ('626454429735088128', 1.6862287441467623),\n",
       " ('626449694328291328', 1.6862287441467623),\n",
       " ('626444103358803968', 1.6862287441467623),\n",
       " ('626443629364662272', 1.6862287441467623),\n",
       " ('626442983454437376', 1.6862287441467623),\n",
       " ('626441817446293504', 1.6862287441467623),\n",
       " ('626431973397893120', 1.6862287441467623),\n",
       " ('626429750412587008', 1.6862287441467623),\n",
       " ('626426084599439360', 1.6862287441467623),\n",
       " ('626425304488112128', 1.6862287441467623),\n",
       " ('626416639022493696', 1.6862287441467623),\n",
       " ('626415288473513985', 1.6862287441467623),\n",
       " ('626415049389817856', 1.6862287441467623),\n",
       " ('626414441215729664', 1.6862287441467623),\n",
       " ('626413510105260033', 1.6862287441467623),\n",
       " ('626412482483978240', 1.6862287441467623),\n",
       " ('626410884441575424', 1.6862287441467623),\n",
       " ('626410611828600832', 1.6862287441467623),\n",
       " ('626409739396648960', 1.6862287441467623),\n",
       " ('626409605195792384', 1.6862287441467623),\n",
       " ('626402273544024064', 1.6862287441467623),\n",
       " ('626400679704158208', 1.6862287441467623),\n",
       " ('626396669970505728', 1.6862287441467623),\n",
       " ('626394413422370816', 1.6862287441467623),\n",
       " ('626392530171654144', 1.6862287441467623),\n",
       " ('626391473223827456', 1.6862287441467623),\n",
       " ('626383592130744320', 1.6862287441467623),\n",
       " ('626382270891331584', 1.6862287441467623),\n",
       " ('626379787867713536', 1.6862287441467623),\n",
       " ('626378504435826689', 1.6862287441467623),\n",
       " ('626377724286910464', 1.6862287441467623),\n",
       " ('626377246144462848', 1.6862287441467623),\n",
       " ('626376184989794304', 1.6862287441467623),\n",
       " ('626363522365063168', 1.6862287441467623),\n",
       " ('626363069405368320', 1.6862287441467623),\n",
       " ('626360221456150528', 1.6862287441467623),\n",
       " ('626358396917313536', 1.6862287441467623),\n",
       " ('626355079243694081', 1.6862287441467623),\n",
       " ('626346757723717632', 1.6862287441467623),\n",
       " ('626345033860521984', 1.6862287441467623),\n",
       " ('626344744491307008', 1.6862287441467623),\n",
       " ('626336347473747968', 1.6862287441467623),\n",
       " ('626333373733191680', 1.6862287441467623),\n",
       " ('626328277632860160', 1.6862287441467623),\n",
       " ('626328172766851072', 1.6862287441467623),\n",
       " ('626327786890887169', 1.6862287441467623),\n",
       " ('626321881302437888', 1.6862287441467623),\n",
       " ('626303682242584576', 1.6862287441467623),\n",
       " ('626300259665362944', 1.6862287441467623),\n",
       " ('626290101082005504', 1.6862287441467623),\n",
       " ('626287689344663552', 1.6862287441467623),\n",
       " ('626286439433637888', 1.6862287441467623),\n",
       " ('626286057785528320', 1.6862287441467623),\n",
       " ('626285319592108032', 1.6862287441467623),\n",
       " ('626284505897299974', 1.6862287441467623),\n",
       " ('626284489120088064', 1.6862287441467623),\n",
       " ('626283658639503360', 1.6862287441467623),\n",
       " ('626274619910135808', 1.6862287441467623),\n",
       " ('626269439957331968', 1.6862287441467623)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Search('Manufacturers of industrial controllers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cc41b4a67708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpostings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "print([postings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_from_file(infile,outfile):\n",
    "    infopen = open(infile,'r',encoding='utf-8')\n",
    "    outopen = open(outfile,'w',encoding='utf-8')\n",
    "    \n",
    "    lines = infopen.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        ID = line[0]\n",
    "        listtemp = [te[0] for te in Search(line[1])]\n",
    "        for i in listtemp:\n",
    "            outopen.write(str(ID) + ' ' + i + '\\n')\n",
    "    infopen.close()\n",
    "    outopen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_from_file('/home/liks/Desktop/query.txt','/home/liks/Documents/实验/IR/实验03/MyAns.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
